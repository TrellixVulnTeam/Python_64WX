{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7dzZc_rYrhN"
   },
   "source": [
    "# CNN   small datasets 학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZSgQnWLYrhV"
   },
   "source": [
    "- Data의 수가 많지 않을 때 CNN을 통한 모형 학습이 어려울 수 있음\n",
    "  - 딥러닝은 많은 수의 데이터를 통해 feature engineering 과정 없이 feature를 찾을 수 있는데 있음 \n",
    "- Data가 많지 않아 CNN 학습에 어려움이 있을 때 사용 가능한 방법\n",
    "    - Data augmentation 활용\n",
    "        - 이미지의 색깔, 각도 등을 약간씩 변형하여 data의 수를 늘림 \n",
    "    - Pre-trained network의 활용\n",
    "        - 매우 큰 데이터셋으로 미리 Training한 모델의 파라미터(가중치)를 가져와서 풀려는 문제에 맞게 모델을 재보정해서 사용하는 것.\n",
    "        - 미리 다양한 데이터를 가지고 학습된 모델을 사용하므로 적은 데이터에도 좋은 성능을 낼 수있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8vvonb2YrhW"
   },
   "source": [
    "## Data for cats vs. dogs\n",
    "- 2013년 Kaggle의 computer vision competition data 활용 https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "- 개와 고양이를 구분하기 위한 문제로 각 12,500개의 이미지를 포함\n",
    "- Medium-resolution color JPEGs\n",
    "- 25000장의 사진 중 4000장의 cats/dogs 사진(2000 cats, 2000 dogs) 만을 사용하여 학습하여 좋은 모형을 만들어 낼 수 있을까?\n",
    "    - 학습: 2000, 검증: 1000, 테스트: 1000\n",
    "    \n",
    "![cats_vs_dogs_samples](https://s3.amazonaws.com/book.keras.io/img/ch5/cats_vs_dogs_samples.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lz3IRzELYrhX"
   },
   "source": [
    "- gdown 패키지 : 구글 드라이브의 공유파일 다운로드 패키지    \n",
    "- `pip install gdown==3.3.1`\n",
    "- 코랩에는 설치 되어 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (3.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (from gdown) (4.60.0)\n",
      "Requirement already satisfied: six in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (from gdown) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests[socks]->gdown) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests[socks]->gdown) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests[socks]->gdown) (2020.12.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "executionInfo": {
     "elapsed": 2176,
     "status": "ok",
     "timestamp": 1619416240522,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "7IXMulBFYrhX",
    "outputId": "edea8ef6-7d49-43d9-ad64-3c22b300c6f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1nBE3N2cXQGwD8JaD0JZ2LmFD-n3D5hVU\n",
      "To: C:\\Users\\mein0\\1.JupyterNoteCodes\\08.DeepLearning\\cats_and_dogs_small.zip\n",
      "90.8MB [00:05, 16.4MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cats_and_dogs_small.zip'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 다운로드\n",
    "# https://drive.google.com/uc?id=공유파일_ID\n",
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=1nBE3N2cXQGwD8JaD0JZ2LmFD-n3D5hVU'\n",
    "fname = 'cats_and_dogs_small.zip'\n",
    "\n",
    "gdown.download(url, fname, quiet=False) #url, 저장할 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Bq1eOGjWu2fI"
   },
   "outputs": [],
   "source": [
    "# 리눅스 명령어로 디렉토리 생성\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZipFile.extractall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('cats_and_dogs_small.zip', 'r') as zf:\n",
    "    zf.extractall('data/cats_and_dogs_small/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "283hnuT_u2br"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "# 압축풀기  -q: 로그남기지 말아라.   -d 압축을 어디에 풀것인지 디렉토리 지정.\n",
    "# !unzip -q cats_and_dogs_small.zip -d data/cats_and_dogs_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zBEjjWgYrha"
   },
   "source": [
    "## Build a network\n",
    "\n",
    "- Input: $150 \\times 150$ 픽셀의 RGB layer \n",
    "- Output: cat or dog (binary classification) \n",
    "- ImageDataGenerator를 이용해 파일시스템에 저장된 이미지데이터셋을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gPubGbIu0uMb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "PTnVaApE0uJ1"
   },
   "outputs": [],
   "source": [
    "#하이퍼파라미터\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT_RATE = 0.5\n",
    "N_EPOCHS = 50\n",
    "N_BATCHS = 20\n",
    "IMAGE_SIZE = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "3SSvr-QF0uDA"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input((IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPool2D(padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPool2D(padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPool2D(padding='same'))\n",
    "\n",
    "    # classification\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(DROPOUT_RATE))\n",
    "    model.add(layers.Dense(units=512, activation='relu'))\n",
    "    # 출력\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid'))  #dog/cat : binary classification\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1482,
     "status": "ok",
     "timestamp": 1619422861546,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "ZXmwh5jo0t_C",
    "outputId": "c072d26e-095c-4799-9947-5630cf37f473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 38, 38, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 19, 19, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               47317504  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 47,688,833\n",
      "Trainable params: 47,688,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE), \n",
    "#               loss='binary_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              sample_weight_mode=None,\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lamHfar30t23"
   },
   "outputs": [],
   "source": [
    "# ImageDataGenerator 생성 => Augmentation, 입력 pipeline\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_dir = 'data/cats_and_dogs_small/train'\n",
    "validation_dir = 'data/cats_and_dogs_small/validation'\n",
    "test_dir = 'data/cats_and_dogs_small/test'\n",
    "\n",
    "# 구글 COLAB사용시 경로\n",
    "# train_dir = '/content/data/cats_and_dogs_small/train'\n",
    "# validation_dir = '/content/data/cats_and_dogs_small/validation'\n",
    "# test_dir = '/content/data/cats_and_dogs_small/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "19WBxIH2rZbI"
   },
   "outputs": [],
   "source": [
    "# 1. ImageDataGenerator - No Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1219,
     "status": "ok",
     "timestamp": 1619419550039,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "5LHgB58crZbI",
    "outputId": "ecd2d117-409c-457b-b174-459454071ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Gen.flow_from_directoy() 이용해서 iterator 생성\n",
    "train_iterator = train_datagen.flow_from_directory(directory=train_dir, # 이미지들의 디렉토리.\n",
    "                                                   target_size=(IMAGE_SIZE,IMAGE_SIZE), #Resize 크기(height, width)\n",
    "                                                   class_mode='binary', #dog/cat => binary\n",
    "                                                   batch_size=N_BATCHS)\n",
    "\n",
    "validation_iterator = test_datagen.flow_from_directory(directory=validation_dir,\n",
    "                                                       target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                       class_mode='binary',\n",
    "                                                       batch_size=N_BATCHS)\n",
    "\n",
    "test_iterator = test_datagen.flow_from_directory(directory=test_dir,\n",
    "                                                       target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                       class_mode='binary',\n",
    "                                                       batch_size=N_BATCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1619419667329,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "DB_COp9SrZbJ",
    "outputId": "2e186bee-b55b-4ed9-b530-df1249432abe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iterator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 759,
     "status": "ok",
     "timestamp": 1619419728680,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "zryVcUAHrZbJ",
    "outputId": "b18039f4-43f8-4516-f318-b483d7da6fce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iterator), len(validation_iterator), len(test_iterator)  #1 에폭당 step 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIfzRaBOYrhj"
   },
   "source": [
    "\n",
    "##  Model Training(학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 491440,
     "status": "ok",
     "timestamp": 1619420420972,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "YPyUjHNurZbK",
    "outputId": "fdd00110-38a2-460f-a481-4ae9408afc50",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 15s 59ms/step - loss: 1.3773 - accuracy: 0.5230 - val_loss: 0.6913 - val_accuracy: 0.5520\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.6915 - accuracy: 0.5315 - val_loss: 0.6881 - val_accuracy: 0.5090\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.6685 - accuracy: 0.5779 - val_loss: 0.6498 - val_accuracy: 0.5990\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.6246 - accuracy: 0.6576 - val_loss: 0.6213 - val_accuracy: 0.6600\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.5745 - accuracy: 0.6886 - val_loss: 0.5863 - val_accuracy: 0.6730\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.5403 - accuracy: 0.7170 - val_loss: 0.5592 - val_accuracy: 0.7060\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.4852 - accuracy: 0.7582 - val_loss: 0.5703 - val_accuracy: 0.6960\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.4535 - accuracy: 0.8015 - val_loss: 0.6141 - val_accuracy: 0.7100\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.3665 - accuracy: 0.8303 - val_loss: 0.6404 - val_accuracy: 0.6870\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.3291 - accuracy: 0.8506 - val_loss: 0.6458 - val_accuracy: 0.7210\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.2369 - accuracy: 0.8934 - val_loss: 0.8199 - val_accuracy: 0.7030\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.1990 - accuracy: 0.9157 - val_loss: 0.8717 - val_accuracy: 0.7100\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.1530 - accuracy: 0.9388 - val_loss: 0.8469 - val_accuracy: 0.6990\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.0884 - accuracy: 0.9750 - val_loss: 1.1032 - val_accuracy: 0.6960\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0954 - accuracy: 0.9583 - val_loss: 1.0563 - val_accuracy: 0.7080\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0537 - accuracy: 0.9832 - val_loss: 1.2376 - val_accuracy: 0.6630\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.0540 - accuracy: 0.9807 - val_loss: 1.2248 - val_accuracy: 0.6990\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0496 - accuracy: 0.9845 - val_loss: 1.4700 - val_accuracy: 0.7120\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 1.1946 - val_accuracy: 0.6950\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0601 - accuracy: 0.9822 - val_loss: 1.4407 - val_accuracy: 0.7060\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 1.4613 - val_accuracy: 0.7250\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 1.8622 - val_accuracy: 0.7250\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0298 - accuracy: 0.9917 - val_loss: 1.7042 - val_accuracy: 0.6910\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 1.7217 - val_accuracy: 0.6950\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 1.8971 - val_accuracy: 0.6730\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.0337 - accuracy: 0.9900 - val_loss: 1.7952 - val_accuracy: 0.6960\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0217 - accuracy: 0.9917 - val_loss: 1.7228 - val_accuracy: 0.6950\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0221 - accuracy: 0.9948 - val_loss: 1.4374 - val_accuracy: 0.6810\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.0939 - accuracy: 0.9690 - val_loss: 1.5385 - val_accuracy: 0.7010\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.0471 - accuracy: 0.9884 - val_loss: 1.5113 - val_accuracy: 0.7000\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0277 - accuracy: 0.9892 - val_loss: 1.8071 - val_accuracy: 0.7190\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.0107 - accuracy: 0.9949 - val_loss: 1.8675 - val_accuracy: 0.7150\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.0426 - accuracy: 0.9907 - val_loss: 1.8923 - val_accuracy: 0.6850\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.0476 - accuracy: 0.9897 - val_loss: 1.7601 - val_accuracy: 0.7000\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 2.0599 - val_accuracy: 0.7130\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 2.0072 - val_accuracy: 0.7100\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 2.0082 - val_accuracy: 0.7130\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 2.0638 - val_accuracy: 0.7000\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 2.3546 - val_accuracy: 0.7060\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 7.0599e-04 - accuracy: 1.0000 - val_loss: 2.2397 - val_accuracy: 0.7100\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 5.7116e-04 - accuracy: 1.0000 - val_loss: 2.2446 - val_accuracy: 0.7180\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 4.4392e-04 - accuracy: 1.0000 - val_loss: 2.3718 - val_accuracy: 0.7030\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 2.4692 - val_accuracy: 0.7020\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 2.6487 - val_accuracy: 0.7050\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0471 - accuracy: 0.9861 - val_loss: 2.2450 - val_accuracy: 0.6810\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 1.8415 - val_accuracy: 0.6860\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0129 - accuracy: 0.9930 - val_loss: 2.3057 - val_accuracy: 0.6960\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0150 - accuracy: 0.9972 - val_loss: 1.8790 - val_accuracy: 0.6930\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 2.1366 - val_accuracy: 0.6940\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 2.3069 - val_accuracy: 0.7120\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_iterator, \n",
    "                    epochs=N_EPOCHS,\n",
    "                    steps_per_epoch=len(train_iterator),\n",
    "                    validation_data=validation_iterator,\n",
    "                    validation_steps=len(validation_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3745,
     "status": "ok",
     "timestamp": 1619421154966,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "5-4Tb1gnrZbL",
    "outputId": "bd66f5a7-c53e-4d06-fae8-98636acce50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 2s 35ms/step - loss: 2.7418 - accuracy: 0.6920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.7418298721313477, 0.6919999718666077]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wgm2cI4WBl67"
   },
   "source": [
    "- Overfitting 발생 \n",
    "    - 원인: 적은 train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "NUQK1HXzrZbM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fAwTvdIYrhm"
   },
   "source": [
    "# Using data augmentation\n",
    "\n",
    "- 학습 이미지의 수가 적어서 overfitting이 발생할 가능성을 줄이기 위해 기존 훈련 데이터로부터 그럴듯하게 이미지 변환을 통해서 이미지(데이터)를 늘리는 작업을 Image augmentation\n",
    "- train_set에만 적용, validation, test set에는 적용하지 않는다. (rescaling만 한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "IuaBH15qrZbM"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   brightness_range=(0.7, 1.3),\n",
    "                                   fill_mode='constant')\n",
    "\n",
    "# validation, test 용\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 824,
     "status": "ok",
     "timestamp": 1619422874990,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "Z_5VAUCmrZbN",
    "outputId": "fd06e7f1-d85c-405d-e16f-1f4ab14ff6fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_iterator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                   target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                   class_mode='binary',\n",
    "                                                   batch_size=N_BATCHS)\n",
    "\n",
    "validation_iterator = test_datagen.flow_from_directory(validation_dir, \n",
    "                                                       target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                       class_mode='binary',\n",
    "                                                       batch_size=N_BATCHS)\n",
    "test_iterator = test_datagen.flow_from_directory(test_dir, \n",
    "                                                 target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                 class_mode='binary',\n",
    "                                                 batch_size=N_BATCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 987,
     "status": "ok",
     "timestamp": 1619421853786,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "Z0MJlBHfrZbN",
    "outputId": "adc14aff-4b9d-4c7f-f719-7773ce14a783"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 150, 150, 3), (20,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 확인\n",
    "batch_image = train_iterator.next()\n",
    "batch_image[0].shape, batch_image[1].shape   #batch_image[0]: image, batch_image[1]: labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4465,
     "status": "ok",
     "timestamp": 1619422088033,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "4U8PuWcfrZbN",
    "outputId": "867159cc-37aa-44c6-b12e-e040ee827c8d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1080 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    img = batch_image[0][i].astype('uint8')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "ewzOopv7rZbN"
   },
   "outputs": [],
   "source": [
    "model2 = create_model()\n",
    "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 941353,
     "status": "ok",
     "timestamp": 1619423832692,
     "user": {
      "displayName": "Sunghwan KIM",
      "photoUrl": "",
      "userId": "06010856989212311727"
     },
     "user_tz": -540
    },
    "id": "wwc0eDyDrZbN",
    "outputId": "c706d730-8fb4-4b50-9caa-5a408f0dcf37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 0.7290 - accuracy: 0.5020 - val_loss: 0.6926 - val_accuracy: 0.5030\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6937 - accuracy: 0.5170 - val_loss: 0.6922 - val_accuracy: 0.5960\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6913 - accuracy: 0.5265 - val_loss: 0.6904 - val_accuracy: 0.5710\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.6942 - accuracy: 0.5290 - val_loss: 0.6927 - val_accuracy: 0.5420\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.6959 - accuracy: 0.5000 - val_loss: 0.6924 - val_accuracy: 0.5030\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.6875 - accuracy: 0.5515 - val_loss: 0.6938 - val_accuracy: 0.5580\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.6924 - accuracy: 0.5065 - val_loss: 0.6911 - val_accuracy: 0.5430\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.6935 - accuracy: 0.5165 - val_loss: 0.6913 - val_accuracy: 0.5390\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.6914 - accuracy: 0.5295 - val_loss: 0.6935 - val_accuracy: 0.5340\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.6845 - accuracy: 0.5895 - val_loss: 0.6920 - val_accuracy: 0.5160\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.6811 - accuracy: 0.5730 - val_loss: 0.6926 - val_accuracy: 0.5220\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6734 - accuracy: 0.5930 - val_loss: 0.6685 - val_accuracy: 0.6030\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6769 - accuracy: 0.5840 - val_loss: 0.6701 - val_accuracy: 0.5870\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.6581 - accuracy: 0.6190 - val_loss: 0.6561 - val_accuracy: 0.6300\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.6503 - accuracy: 0.6385 - val_loss: 0.6828 - val_accuracy: 0.5990\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6465 - accuracy: 0.6415 - val_loss: 0.6567 - val_accuracy: 0.6210\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.6302 - accuracy: 0.6585 - val_loss: 0.6593 - val_accuracy: 0.6310\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.6457 - accuracy: 0.6245 - val_loss: 0.6772 - val_accuracy: 0.6080\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.6363 - accuracy: 0.6400 - val_loss: 0.6632 - val_accuracy: 0.6470\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.6274 - accuracy: 0.6555 - val_loss: 0.6695 - val_accuracy: 0.6030\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6361 - accuracy: 0.6460 - val_loss: 0.6598 - val_accuracy: 0.6160\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6372 - accuracy: 0.6505 - val_loss: 0.6468 - val_accuracy: 0.6540\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.6271 - accuracy: 0.6485 - val_loss: 0.6475 - val_accuracy: 0.6260\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.6222 - accuracy: 0.6525 - val_loss: 0.6264 - val_accuracy: 0.6610\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.6255 - accuracy: 0.6530 - val_loss: 0.6196 - val_accuracy: 0.6570\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.6068 - accuracy: 0.6710 - val_loss: 0.6171 - val_accuracy: 0.6540\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.6058 - accuracy: 0.6605 - val_loss: 0.6464 - val_accuracy: 0.6450\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.6065 - accuracy: 0.6625 - val_loss: 0.6195 - val_accuracy: 0.6640\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.5906 - accuracy: 0.6765 - val_loss: 0.6208 - val_accuracy: 0.6610\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6009 - accuracy: 0.6740 - val_loss: 0.6054 - val_accuracy: 0.6730\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.6022 - accuracy: 0.6635 - val_loss: 0.6296 - val_accuracy: 0.6470\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5994 - accuracy: 0.6755 - val_loss: 0.6062 - val_accuracy: 0.6610\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.5859 - accuracy: 0.6675 - val_loss: 0.6277 - val_accuracy: 0.6330\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5806 - accuracy: 0.6865 - val_loss: 0.6135 - val_accuracy: 0.6580\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.5877 - accuracy: 0.6880 - val_loss: 0.6159 - val_accuracy: 0.6400\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5658 - accuracy: 0.7000 - val_loss: 0.6378 - val_accuracy: 0.6690\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.5710 - accuracy: 0.7010 - val_loss: 0.7040 - val_accuracy: 0.6390\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5803 - accuracy: 0.6895 - val_loss: 0.5965 - val_accuracy: 0.6940\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.5730 - accuracy: 0.6995 - val_loss: 0.5790 - val_accuracy: 0.6790\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.5841 - accuracy: 0.6825 - val_loss: 0.6062 - val_accuracy: 0.6660\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.5627 - accuracy: 0.6870 - val_loss: 0.5852 - val_accuracy: 0.6910\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5716 - accuracy: 0.7030 - val_loss: 0.5885 - val_accuracy: 0.6700\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.5608 - accuracy: 0.7180 - val_loss: 0.5695 - val_accuracy: 0.6830\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5547 - accuracy: 0.7155 - val_loss: 0.5770 - val_accuracy: 0.6800\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.5508 - accuracy: 0.7175 - val_loss: 0.6005 - val_accuracy: 0.6820\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5621 - accuracy: 0.7060 - val_loss: 0.5909 - val_accuracy: 0.6820\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5632 - accuracy: 0.7100 - val_loss: 0.5720 - val_accuracy: 0.6930\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5375 - accuracy: 0.7080 - val_loss: 0.6064 - val_accuracy: 0.6900\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.5315 - accuracy: 0.7225 - val_loss: 0.6451 - val_accuracy: 0.6760\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.5303 - accuracy: 0.7260 - val_loss: 0.6050 - val_accuracy: 0.6790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19b06f30788>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_iterator, \n",
    "           epochs=N_EPOCHS,\n",
    "           steps_per_epoch=len(train_iterator),\n",
    "           validation_data=validation_iterator,\n",
    "           validation_steps=len(validation_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "EWApiSxlrZbO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.9983 - accuracy: 0.5290 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6903 - accuracy: 0.5475 - val_loss: 0.6758 - val_accuracy: 0.5460\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.6865 - accuracy: 0.5660 - val_loss: 0.6365 - val_accuracy: 0.6410\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.6387 - accuracy: 0.6260 - val_loss: 0.6189 - val_accuracy: 0.6600\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.6339 - accuracy: 0.6590 - val_loss: 0.5779 - val_accuracy: 0.7130\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.6096 - accuracy: 0.6720 - val_loss: 0.5700 - val_accuracy: 0.7040\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.6004 - accuracy: 0.6790 - val_loss: 0.5771 - val_accuracy: 0.6970\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5882 - accuracy: 0.6850 - val_loss: 0.5414 - val_accuracy: 0.7410\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.5567 - accuracy: 0.7185 - val_loss: 0.5755 - val_accuracy: 0.7140\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5612 - accuracy: 0.7065 - val_loss: 0.5526 - val_accuracy: 0.7260\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.5538 - accuracy: 0.7140 - val_loss: 0.5283 - val_accuracy: 0.7290\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.5392 - accuracy: 0.7255 - val_loss: 0.5486 - val_accuracy: 0.7270\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.5475 - accuracy: 0.7270 - val_loss: 0.5370 - val_accuracy: 0.7220\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5404 - accuracy: 0.7215 - val_loss: 0.5320 - val_accuracy: 0.7280\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.5224 - accuracy: 0.7505 - val_loss: 0.5159 - val_accuracy: 0.7400\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5321 - accuracy: 0.7360 - val_loss: 0.5501 - val_accuracy: 0.7050\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.5110 - accuracy: 0.7485 - val_loss: 0.4842 - val_accuracy: 0.7560\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.4943 - accuracy: 0.7595 - val_loss: 0.5102 - val_accuracy: 0.7540\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.5052 - accuracy: 0.7565 - val_loss: 0.4980 - val_accuracy: 0.7520\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.4996 - accuracy: 0.7620 - val_loss: 0.5053 - val_accuracy: 0.7420\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.4884 - accuracy: 0.7580 - val_loss: 0.5035 - val_accuracy: 0.7670\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.4805 - accuracy: 0.7675 - val_loss: 0.4980 - val_accuracy: 0.7540\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.4940 - accuracy: 0.7540 - val_loss: 0.5215 - val_accuracy: 0.7350\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.4779 - accuracy: 0.7695 - val_loss: 0.5132 - val_accuracy: 0.7590\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.4710 - accuracy: 0.7800 - val_loss: 0.4809 - val_accuracy: 0.7600\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.4743 - accuracy: 0.7675 - val_loss: 0.4552 - val_accuracy: 0.7870\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.4879 - accuracy: 0.7645 - val_loss: 0.4651 - val_accuracy: 0.7900\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.4742 - accuracy: 0.7715 - val_loss: 0.4688 - val_accuracy: 0.7850\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.4713 - accuracy: 0.7790 - val_loss: 0.5132 - val_accuracy: 0.7590\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.4605 - accuracy: 0.7780 - val_loss: 0.4583 - val_accuracy: 0.7960\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.4727 - accuracy: 0.7765 - val_loss: 0.4662 - val_accuracy: 0.7780\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.4649 - accuracy: 0.7825 - val_loss: 0.4645 - val_accuracy: 0.7930\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.4378 - accuracy: 0.7955 - val_loss: 0.4695 - val_accuracy: 0.7880\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.4483 - accuracy: 0.7780 - val_loss: 0.4718 - val_accuracy: 0.7780\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.4538 - accuracy: 0.7810 - val_loss: 0.4996 - val_accuracy: 0.7820\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.4520 - accuracy: 0.7915 - val_loss: 0.4619 - val_accuracy: 0.7860\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.4419 - accuracy: 0.7860 - val_loss: 0.4583 - val_accuracy: 0.7880\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.4335 - accuracy: 0.7995 - val_loss: 0.4579 - val_accuracy: 0.7940\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.4316 - accuracy: 0.8050 - val_loss: 0.4721 - val_accuracy: 0.7740\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.4241 - accuracy: 0.8015 - val_loss: 0.4544 - val_accuracy: 0.7840\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.4400 - accuracy: 0.7975 - val_loss: 0.4605 - val_accuracy: 0.7860\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.4232 - accuracy: 0.8075 - val_loss: 0.4934 - val_accuracy: 0.7800\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.4404 - accuracy: 0.8005 - val_loss: 0.4871 - val_accuracy: 0.7770\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.4402 - accuracy: 0.7920 - val_loss: 0.4464 - val_accuracy: 0.7990\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.4209 - accuracy: 0.8130 - val_loss: 0.4853 - val_accuracy: 0.7820\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 0.4232 - accuracy: 0.8160 - val_loss: 0.4728 - val_accuracy: 0.7810\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.4139 - accuracy: 0.8085 - val_loss: 0.4613 - val_accuracy: 0.7930\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.4297 - accuracy: 0.8060 - val_loss: 0.4486 - val_accuracy: 0.7910\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.4015 - accuracy: 0.8220 - val_loss: 0.4705 - val_accuracy: 0.7790\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.3966 - accuracy: 0.8185 - val_loss: 0.4971 - val_accuracy: 0.7900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19b0977e288>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_iterator, \n",
    "           epochs=N_EPOCHS,\n",
    "           steps_per_epoch=len(train_iterator),\n",
    "           validation_data=validation_iterator,\n",
    "           validation_steps=len(validation_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMnde82MrZbO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LLVXR6QrZbO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hy1h_9o0rZbO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ql8F1bCZYrhr"
   },
   "source": [
    "###  DataFrame 이용\n",
    "- flow_from_dataframe() 사용\n",
    "    - 파일경로와 label을 DataFrame으로 저장하고 그것을 이용해 데이터셋을 읽어온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cats_and_dogs_union.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=17ejPJw42TgTv0jCPMMlVTHwF57XYE2kb'\n",
    "fname = 'cats_and_dogs_union.zip'\n",
    "gdown.download(url,fname, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('cats_and_dogs_union.zip', 'r') as zf:\n",
    "    zf.extractall('../../1. Data/data2/cats_and_dogs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글드라이브사용시\n",
    "# !mkdir data\n",
    "# !unzip -q ./cats_and_dogs_union.zip -d ./data/cats_and_dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame 생성\n",
    "- path, label 컬럼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "bEqMC8CWrZbO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#파일 경로 다루기 - glob\n",
    "from glob import glob\n",
    "# ** 모든 하위경로, *.jpg (확장자가 jpg인 모든 파일)\n",
    "# path_list = glob(\"/content/data/cats_and_dogs/**/*.jpg\") #지정한 파일들의 absolute path(절대경로)를 문자열로 반환 (리스트에 담아서 반환.)\n",
    "path_list = glob(\"..\\\\..\\\\1. Data\\data2\\cats_and_dogs\\**\\*.jpg\") #지정한 파일들의 absolute path(절대경로)를 문자열로 반환 (리스트에 담아서 반환.)\n",
    "len(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Kb8yFH2rrZbP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\cats\\\\cat.0.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\cats\\\\cat.1.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\cats\\\\cat.10.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\cats\\\\cat.100.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\cats\\\\cat.1000.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\cats\\\\cat.1001.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\cats\\\\cat.1002.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\cats\\\\cat.1003.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\cats\\\\cat.1004.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\cats\\\\cat.1005.jpg'],\n",
       " ['..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\dogs\\\\dog.990.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\dogs\\\\dog.991.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\dogs\\\\dog.992.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\dogs\\\\dog.993.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\dogs\\\\dog.994.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\dogs\\\\dog.995.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\dogs\\\\dog.996.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\dogs\\\\dog.997.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\dogs\\\\dog.998.jpg',\n",
       "  '..\\\\..\\\\1. Data\\\\data2\\\\cats_and_dogs\\\\dogs\\\\dog.999.jpg'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list[:10], path_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HKzfKZUNrZbP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog.1999.jpg\n",
      "../../1. Data/data2/cats_and_dogs/dogs\n",
      "dogs\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "f = '../../1. Data/data2/cats_and_dogs/dogs/dog.1999.jpg'\n",
    "\n",
    "print(os.path.basename(f)) # basename(경로): 경로에서 파일명만 추출\n",
    "print(os.path.dirname(f)) # dirname(경로): 경로에서 디렉토리 부분만 추출\n",
    "print(os.path.dirname(f).split(r'/')[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "TR4Vyq9XrZbP"
   },
   "outputs": [],
   "source": [
    "label_list = []\n",
    "for path in path_list:\n",
    "    l = os.path.dirname(path).split('\\\\')[5]\n",
    "    label_list.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "j3ah4YESrZbP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cats', 'cats', 'cats', 'cats', 'cats'],\n",
       " ['dogs', 'dogs', 'dogs', 'dogs', 'dogs'],\n",
       " 4000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = [os.path.dirname(path).split('\\\\')[5] for path in path_list]\n",
    "label_list[:5], label_list[-5:], len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "pU5f1nMcrZbP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {\n",
    "    \"path\":path_list,\n",
    "    \"label\":label_list\n",
    "}\n",
    "data_df = pd.DataFrame(d)\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "dPgVUmWVrZbQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\1. Data\\data2\\cats_and_dogs\\cats\\cat.0.jpg</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\1. Data\\data2\\cats_and_dogs\\cats\\cat.1.jpg</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\1. Data\\data2\\cats_and_dogs\\cats\\cat.10.jpg</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\1. Data\\data2\\cats_and_dogs\\cats\\cat.100...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\1. Data\\data2\\cats_and_dogs\\cats\\cat.100...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path label\n",
       "0   ..\\..\\1. Data\\data2\\cats_and_dogs\\cats\\cat.0.jpg  cats\n",
       "1   ..\\..\\1. Data\\data2\\cats_and_dogs\\cats\\cat.1.jpg  cats\n",
       "2  ..\\..\\1. Data\\data2\\cats_and_dogs\\cats\\cat.10.jpg  cats\n",
       "3  ..\\..\\1. Data\\data2\\cats_and_dogs\\cats\\cat.100...  cats\n",
       "4  ..\\..\\1. Data\\data2\\cats_and_dogs\\cats\\cat.100...  cats"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "ZpYgYbw4rZbQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>..\\..\\1. Data\\data2\\cats_and_dogs\\dogs\\dog.995...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>..\\..\\1. Data\\data2\\cats_and_dogs\\dogs\\dog.996...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>..\\..\\1. Data\\data2\\cats_and_dogs\\dogs\\dog.997...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>..\\..\\1. Data\\data2\\cats_and_dogs\\dogs\\dog.998...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>..\\..\\1. Data\\data2\\cats_and_dogs\\dogs\\dog.999...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path label\n",
       "3995  ..\\..\\1. Data\\data2\\cats_and_dogs\\dogs\\dog.995...  dogs\n",
       "3996  ..\\..\\1. Data\\data2\\cats_and_dogs\\dogs\\dog.996...  dogs\n",
       "3997  ..\\..\\1. Data\\data2\\cats_and_dogs\\dogs\\dog.997...  dogs\n",
       "3998  ..\\..\\1. Data\\data2\\cats_and_dogs\\dogs\\dog.998...  dogs\n",
       "3999  ..\\..\\1. Data\\data2\\cats_and_dogs\\dogs\\dog.999...  dogs"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "jU8gMcPerZbQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cats    2000\n",
       "dogs    2000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "r8BEXkaTrZbQ"
   },
   "outputs": [],
   "source": [
    "data_df.to_csv('cats_and_dogs_filelist.csv', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "2ncAkEwnrZbQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 2), (2000, 2))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cats, dogs DataFrame으로 분리\n",
    "cats_df = data_df[data_df['label']=='cats']\n",
    "dogs_df = data_df[data_df['label']=='dogs']\n",
    "cats_df.shape, dogs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "NGflpHwYrZbR"
   },
   "outputs": [],
   "source": [
    "# train/test dataframe을 생성   8:2\n",
    "split_idx = int(dogs_df.shape[0]*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "dw9uNvLxrZbR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cats    1600\n",
       "dogs    1600\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([dogs_df[:split_idx], cats_df[:split_idx]], axis=0) #dogs, cats의 0 ~ 1599 (1600)개를 묶어서 train_df 생성\n",
    "train_df.shape\n",
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "r0Enaq3jrZbR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cats    400\n",
       "dogs    400\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.concat([dogs_df[split_idx:], cats_df[split_idx:]], axis=0)\n",
    "print(test_df.shape)\n",
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   brightness_range=(0.7, 1.3),\n",
    "                                   fill_mode='constant')\n",
    "\n",
    "# validation, test 용\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 validated image filenames belonging to 2 classes.\n",
      "Found 800 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_iterator = train_datagen.flow_from_dataframe(dataframe=train_df, #path, label을 가진 DataFrame객체를 지정\n",
    "                                                   x_col='path',  #이미지 경로를 가진 컬럼명\n",
    "                                                   y_col='label', # label 컬럼명\n",
    "                                                   target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                   class_mode='binary',\n",
    "                                                   batch_size=N_BATCHS)\n",
    "\n",
    "test_iterator = test_datagen.flow_from_dataframe(test_df,\n",
    "                                                 x_col='path',\n",
    "                                                 y_col='label',\n",
    "                                                 target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                 class_mode='binary',\n",
    "                                                 batch_size=N_BATCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iterator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 38, 38, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 19, 19, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               47317504  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 47,688,833\n",
      "Trainable params: 47,688,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE), \n",
    "#               loss='binary_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "160/160 [==============================] - 23s 115ms/step - loss: 0.8514 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 18s 115ms/step - loss: 0.6933 - accuracy: 0.4876 - val_loss: 0.6917 - val_accuracy: 0.4975\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6944 - accuracy: 0.5164 - val_loss: 0.6928 - val_accuracy: 0.4925\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 18s 115ms/step - loss: 0.6945 - accuracy: 0.5131 - val_loss: 0.6928 - val_accuracy: 0.5075\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 18s 115ms/step - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6893 - val_accuracy: 0.5025\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 19s 116ms/step - loss: 0.6905 - accuracy: 0.5186 - val_loss: 0.6887 - val_accuracy: 0.5512\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6792 - accuracy: 0.5441 - val_loss: 0.6788 - val_accuracy: 0.5437\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6816 - accuracy: 0.5651 - val_loss: 0.7096 - val_accuracy: 0.5188\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6888 - accuracy: 0.5478 - val_loss: 0.6543 - val_accuracy: 0.5850\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 18s 115ms/step - loss: 0.6676 - accuracy: 0.5698 - val_loss: 0.6510 - val_accuracy: 0.6075\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6546 - accuracy: 0.6031 - val_loss: 0.6547 - val_accuracy: 0.5750\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6434 - accuracy: 0.6117 - val_loss: 0.6811 - val_accuracy: 0.5675\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.6560 - accuracy: 0.6074 - val_loss: 0.6561 - val_accuracy: 0.6162\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6331 - accuracy: 0.6343 - val_loss: 0.6339 - val_accuracy: 0.6250\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6362 - accuracy: 0.6196 - val_loss: 0.6351 - val_accuracy: 0.6313\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6358 - accuracy: 0.6399 - val_loss: 0.6142 - val_accuracy: 0.6662\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6206 - accuracy: 0.6425 - val_loss: 0.5972 - val_accuracy: 0.6850\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6246 - accuracy: 0.6315 - val_loss: 0.6149 - val_accuracy: 0.6725\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6250 - accuracy: 0.6427 - val_loss: 0.5889 - val_accuracy: 0.6800\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.6134 - accuracy: 0.6507 - val_loss: 0.5928 - val_accuracy: 0.7025\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.6021 - accuracy: 0.6643 - val_loss: 0.6121 - val_accuracy: 0.6862\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5891 - accuracy: 0.6751 - val_loss: 0.5773 - val_accuracy: 0.6975\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.5887 - accuracy: 0.6847 - val_loss: 0.6065 - val_accuracy: 0.6650\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 18s 115ms/step - loss: 0.5892 - accuracy: 0.6755 - val_loss: 0.5721 - val_accuracy: 0.6975\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 18s 115ms/step - loss: 0.6025 - accuracy: 0.6684 - val_loss: 0.5580 - val_accuracy: 0.7212\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5938 - accuracy: 0.6736 - val_loss: 0.5426 - val_accuracy: 0.7287\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5867 - accuracy: 0.6763 - val_loss: 0.5415 - val_accuracy: 0.7400\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5778 - accuracy: 0.6963 - val_loss: 0.5485 - val_accuracy: 0.7375\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5708 - accuracy: 0.7012 - val_loss: 0.5608 - val_accuracy: 0.7150\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5699 - accuracy: 0.6840 - val_loss: 0.5523 - val_accuracy: 0.7262\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5681 - accuracy: 0.6984 - val_loss: 0.5405 - val_accuracy: 0.7312\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5662 - accuracy: 0.6973 - val_loss: 0.5337 - val_accuracy: 0.7312\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5615 - accuracy: 0.7085 - val_loss: 0.5330 - val_accuracy: 0.7400\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5631 - accuracy: 0.6961 - val_loss: 0.5475 - val_accuracy: 0.7262\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5425 - accuracy: 0.7252 - val_loss: 0.5445 - val_accuracy: 0.7337\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5510 - accuracy: 0.7165 - val_loss: 0.5386 - val_accuracy: 0.7400\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.5550 - accuracy: 0.7109 - val_loss: 0.5518 - val_accuracy: 0.7200\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 18s 114ms/step - loss: 0.5550 - accuracy: 0.7106 - val_loss: 0.5264 - val_accuracy: 0.7350\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 18s 112ms/step - loss: 0.5521 - accuracy: 0.7134 - val_loss: 0.5401 - val_accuracy: 0.7113\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 18s 112ms/step - loss: 0.5390 - accuracy: 0.7168 - val_loss: 0.5088 - val_accuracy: 0.7638\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.5396 - accuracy: 0.7113 - val_loss: 0.4996 - val_accuracy: 0.7763\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.5263 - accuracy: 0.7315 - val_loss: 0.5293 - val_accuracy: 0.7287\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.5184 - accuracy: 0.7349 - val_loss: 0.5035 - val_accuracy: 0.7563\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.5358 - accuracy: 0.7134 - val_loss: 0.5031 - val_accuracy: 0.7650\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 18s 112ms/step - loss: 0.5238 - accuracy: 0.7518 - val_loss: 0.5118 - val_accuracy: 0.7625\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.5316 - accuracy: 0.7308 - val_loss: 0.4990 - val_accuracy: 0.7525\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.5196 - accuracy: 0.7472 - val_loss: 0.4994 - val_accuracy: 0.7638\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.5248 - accuracy: 0.7314 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 18s 112ms/step - loss: 0.5258 - accuracy: 0.7364 - val_loss: 0.4859 - val_accuracy: 0.7887\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 18s 113ms/step - loss: 0.5184 - accuracy: 0.7300 - val_loss: 0.4799 - val_accuracy: 0.7825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc99e4f688>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_iterator,\n",
    "          epochs=N_EPOCHS,\n",
    "          steps_per_epoch=len(train_iterator),\n",
    "          validation_data=test_iterator,\n",
    "          validation_steps=len(test_iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def predict_cat_dog(path):\n",
    "    class_name = ['cat','dog']\n",
    "    img = load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    # image -> ndarray\n",
    "    sample = img_to_array(img)[np.newaxis,...]\n",
    "    # scaling\n",
    "    sample = sample/255.\n",
    "    pred = model.predict(sample) # 확률\n",
    "    print(pred)\n",
    "    pred = pred[0,0]\n",
    "    print(pred)\n",
    "    pred_class = np.where(pred < 0.5, 0, 1)\n",
    "    print(pred_class)\n",
    "    pred_class_name = class_name[pred_class]\n",
    "    return pred, pred_class, pred_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27502316]]\n",
      "0.27502316\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.27502316, array(0), 'cat')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cat_dog('cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97358704]]\n",
      "0.97358704\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.97358704, array(1), 'dog')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cat_dog('dog.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z459JCf1rZbR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuVJEP0CvDis"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "08_2_CNN_Image Augmentation.ipynb",
   "provenance": [
    {
     "file_id": "1I6b7eOQ1H27aeQnoSyPf0BmHkhdNBMV0",
     "timestamp": 1619441859144
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
