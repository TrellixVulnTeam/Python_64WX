{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Feature vectorization 개요\n",
    "- 텍스트를 숫자형값의 정형테이터로 변환하는 것을 Feature vectorization(피처 벡터화) 라고 한다.\n",
    "\n",
    "## BOW (Bag Of Words)\n",
    "**많이 나온 단어가 중요한 단어**\n",
    "- 문서내에 단어 빈도수에 기반하여 Vector화 하는 모델\n",
    "- DTM/TDM (Document Term Matrix)\n",
    "    - 문서안에서 문서를 구성하는 단어들이 몇번 나왔는지를 표현하는 행렬\n",
    "    - 행:단어, 열: 문서 - DTM\n",
    "    - 행:문서, 열:단어 - TDM\n",
    "    - Value: 개수\n",
    "- TF-IDF (Term Frequency Inverse Document Frequency)\n",
    "    - CountVectorize의 문제: 문장 구조상 많이 나오는 단어들의 경우 카운트 값이 많이 나오게 되고 중요한 단어로 인식된다. (ex: 관사, 접속사, 주제어 등) 이 문제를 보완한 모델이 TF-IDF 모델이다.\n",
    "    - 개별 문서에 많이 나오는 단어가 높은 값을 가지도록 하되 동시에 여러 문서에 자주 나오는 단어에는 페널티를 주는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM/TDM (Document Term Matrix)\n",
    "\n",
    "- 단어들이 각 문서에 몇번 나왔는지 행렬로 구성\n",
    "- 많이 나온 단어가 중요한 단어라는 것을 기반으로 한다.\n",
    "- 문서 단어 행렬(Document Term Matrix)\n",
    "    - 문서별로 각 단어가 나타난 **횟수를 정리한 표**\n",
    "    - 컬럼(Feature): 전체 문서에 나오는 모든 단어\n",
    "    - 행 : 문서\n",
    "    - 값(value) : 각 단어가 문서에 나온 횟수\n",
    "- 단어 문서 행렬(Term Document Matrix)\n",
    "    - DTM을 전치 시킨 것\n",
    "    - 컬럼(Feature): 문서\n",
    "    - 행: 전체 문서에 나오는 모든 단어\n",
    "    - 값(value) : 각 단어가 문서에 나온 횟수\n",
    "- scikit-learn의 CountVectorize 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer \n",
    "#### 주요 생성자 매개변수\n",
    "- stop_word :stopword 지정 \n",
    "    - str: \"english\" - 영문 불용어는 제공됨\n",
    "    - list: stopword 리스트\n",
    "- max_df: 특정 횟수 이상나오는 것은 무시하도록 설정(무시할 횟수/비율 지정)\n",
    "    - int(횟수), float(비율)\n",
    "- min_df: 특정 횟수 이하로 나오는 것은 무시하도록 설정(무시할 횟수/비율 지정)\n",
    "- max_features: 최대 token 수\n",
    "    - 빈도수가 높은 순서대로 정렬 후 지정한 max_features 개수만큼만 사용한다.\n",
    "- ngram_range: n_gram 범위 지정\n",
    "    - n_gram:\n",
    "    - 튜플 (범위 최소값, 범위 최대값)\n",
    "    - (1, 2) : 토큰화된 단어를 1개씩 그리고 순서대로 2개씩 묶어서 Feature를 추출\n",
    "\n",
    "#### 메소드\n",
    "- fit(X)\n",
    "    - 학습\n",
    "    - 매개변수: raw document - 문장을 원소로 가지는 1차원 배열형태(list, ndarray) \n",
    "    - **Train(훈련) 데이터셋 으로 학습한다. Test 데이터셋은 Train 셋으로 학습한 CountVectorizer를 이용해 변환만 한다.**\n",
    "- transform(X)\n",
    "    - DTM 변환\n",
    "- fit_transform(X)\n",
    "    - 학습/변환 한번에 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-gram\n",
    "DTM는 문맥상에서 단어의 의미는 무시된다. 이것을 보완하는 것이 n-gram 기법이다.   \n",
    "n개의 단어를 묶어서 feature로 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:14:29.146772Z",
     "start_time": "2019-12-29T14:14:29.142786Z"
    }
   },
   "outputs": [],
   "source": [
    "train = [\"He really likes football. He wants to be a football player.\", \n",
    "         \"Football is a popular sport in Europe.\", \n",
    "         \"Which country started football?\"]\n",
    "test = [\"He really likes baseball. He wants to be a baseball player.\", \n",
    "        \"Baseball is a popular sport in Korea.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train 셋을 이용해 학습 및 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 셋 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "- 개별 문서에 많이 나오는 단어가 높은 값을 가지도록 하되 동시에 여러 문서에 자주 나오는 단어에는 페널티를 주는 방식\n",
    "- 어떤 문서에 특정 단어가 많이 나오면 그 단어는 해당 문서를 설명하는 중요한 단어일 수 있다. 그러나 그 단어가 다른 문서에도 많이 나온다면 언어 특성이나 주제상 많이 사용되는 단어 일 수 있다.\n",
    "    - 전체 문서에 고르게 많이 나오는 단어들은 각각의 문서가 다른 문서와 다른 특징을 찾는데 도움이 안된다. 그래서 페널티를 주어 작은 값이 되도록 한다.\n",
    "- 각 문서의 길이가 길고 문서개수가 많은 경우 Count 방식 보다 TF-IDF 방식이 더 좋은 예측 성능을 내는 경우가 많다.\n",
    "\n",
    "### 공식\n",
    "- TF (Term Frequency) : 해당 단어가 해당 문서에 몇번 나오는지를 나타내는 지표\n",
    "- DF (Document Frequency) : 해당 단어가 몇개의 문서에 나오는지를 나타내는 지표\n",
    "- IDF (Inverse Document Frequency) : DF에 역수로 $\\cfrac{전체 문서수}{해당단어가 나오는 문서수}$\n",
    "- TF-IDF : $TF * \\left(\\log \\cfrac{전체 문서수}{해당단어가 나오는 문서수} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주요 생성자 매개변수\n",
    "- stop_word :stopword 지정 \n",
    "    - str: \"english\" - 영문 불용어는 제공됨\n",
    "    - list: stopword 리스트\n",
    "- max_df: 특정 횟수 이상나오는 것은 무시하도록 설정(무시할 횟수/비율 지정)\n",
    "    - int(횟수), float(비율)\n",
    "- min_df: 특정 횟수 이하로 나오는 것은 무시하도록 설정(무시할 횟수/비율 지정)\n",
    "- max_features: 최대 token 수\n",
    "    - 빈도수가 높은 순서대로 정렬 후 지정한 max_features 개수만큼만 사용한다.\n",
    "- ngram_range: n_gram 범위 지정\n",
    "    - n_gram:\n",
    "    - 튜플 (범위 최소값, 범위 최대값)\n",
    "    - (1, 2) : 토큰화된 단어를 1개씩 그리고 순서대로 2개씩 묶어서 Feature를 추출\n",
    "\n",
    "#### 메소드\n",
    "- fit(X)\n",
    "    - 학습\n",
    "    - 매개변수: 문장을 가진 1차원 배열형태(list, ndarray) \n",
    "    - **Train(훈련) 데이터셋 으로 학습한다. Test 데이터셋은 Train 셋으로 학습한 CountVectorizer를 이용해 변환만 한다.**\n",
    "- transform(X)\n",
    "    - DTM 변환\n",
    "- fit_transform(X)\n",
    "    - 학습/변환 한번에 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T15:49:12.882276Z",
     "start_time": "2019-12-29T15:49:12.878294Z"
    }
   },
   "outputs": [],
   "source": [
    "train = [\"He really likes football. He wants to be a football player.\", \n",
    "         \"Football is a popular sport in Europe.\", \n",
    "         \"Which country started football?\"]\n",
    "test = [\"He really likes baseball. He wants to be a baseball player.\", \n",
    "        \"Baseball is a popular sport in Korea.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB(Internet Movie Database)  영화리뷰 데이터 셋\n",
    "- https://www.imdb.com/\n",
    "- 다운로드: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "    - train의 unsup 은 제거 (비지도학습용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load_files() \n",
    "    - 분류범주를 폴더로 분리한 텍스트 파일을 load한다.\n",
    "    - Bunch 타입으로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- neg: 0, pos: 1 로 분리해 준다. (폴더의 알파벳 순서대로 )\n",
    "- Bunch 타입으로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리\n",
    "- `<br/>` 제거\n",
    "- binary string을 string으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리한 데이터셋 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vectorization \n",
    "\n",
    "### DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머신러닝 알고리즘을 이용해 긍부정 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머신러닝 알고리즘을 이용해 긍부정 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "494px",
    "left": "1046px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
