{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF_ODA2_PATH = r'..\\..\\..\\1_playdataInstalls\\TF_oda2\\models\\research'\n",
    "\n",
    "BASE_PATH = r'..\\..\\..\\1.Data\\object_detection_workspace\\workspace' #  작업시 생기는 파일들을 저장할 root디렉토리.\n",
    "SCRIPT_PATH = r'..\\..\\..\\1.Data\\object_detection_workspace\\scripts' # utility python script들이 저장된 디렉토리.\n",
    "TF_OD_API_PATH = r'..\\..\\..\\1_playdataInstalls\\TF_oda2\\models' # Tensorflow object detection api 설치 경로.\n",
    "\n",
    "IMAGE_PATH = os.path.join(BASE_PATH, 'images') # image data들, annotation 파일이 저장된 디렉토리.\n",
    "\n",
    "LABEL_MAP_PATH = os.path.join(BASE_PATH, 'labelmap') # Label map파일이 저장된 디렉토리.\n",
    "LABEL_MAP_FILE_PATH = os.path.join(LABEL_MAP_PATH, 'label_map.pbtxt') # Label_map파일 경로\n",
    "\n",
    "TF_RECORD_PATH = os.path.join(BASE_PATH, 'tfrecord') # TFRecord파일들을 저장할 경로.\n",
    "\n",
    "MODEL_PATH = os.path.join(BASE_PATH, 'model') # pretrained 모델 fine tuning한 모델, weight(ckpt), pipeline.config를 저장할 경로.\n",
    "CHECK_POINT_PATH = os.path.join(MODEL_PATH, 'checkpoint') # 학습도중에 중간 중간 저장되는 weight\n",
    "EXPORT_MODEL_PATH = os.path.join(MODEL_PATH, 'export_model') # fine tuning한 최종 모델을 저장할 경로\n",
    "PIPELINE_CONFIG_PATH = os.path.join(MODEL_PATH, 'pipeline.config') # pipeline.config(설정파일)의 경로.\n",
    "\n",
    "PRE_TRAINED_MODEL_PATH = os.path.join(BASE_PATH, 'pre_trained_model') # 전이학습 시킬 model을 저장할 경로."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\..\\\\..\\\\1.Data\\\\object_detection_workspace\\\\workspace\\\\pre_trained_model'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRE_TRAINED_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.;C:\\\\Users\\\\mein0\\\\1_playdataInstalls\\\\TF_oda2\\\\models;C:\\\\Users\\\\mein0\\\\1_playdataInstalls\\\\TF_oda2\\\\models\\\\research;'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PYTHONPATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (4.5.2.52)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\mein0\\anaconda3\\envs\\tf2\\lib\\site-packages (from opencv-python) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util, config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x20a1a1a1888>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline.config에 맞춰서 추출한 모델을 바탕으로 모델을 생성\n",
    "\n",
    "# pipeline.config를 조회\n",
    "config = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH)\n",
    "# print(config)\n",
    "#config 정보를 넣어서 모델생성\n",
    "detection_model = model_builder.build(model_config=config['model'], is_training=False)\n",
    "\n",
    "# 모델에 학습시킨 checkpoint(weight)를 주입\n",
    "# checkpoint 조회\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECK_POINT_PATH,'ckpt-21')).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detection을 실행하는 함수\n",
    "\n",
    "# 순전파 처리 함수에 @tf.function decorator를 선언하면 실행 속도가 빨라진다.\n",
    "@tf.function\n",
    "def detect_func(image):\n",
    "    \"\"\"\n",
    "    매개변수로 object detection을 수행할 대상 image(Tensor)를 받아서 detection처리.\n",
    "    1. preprocessing(전처리): resize, normalization 작업\n",
    "    2. detection(inference-추론)\n",
    "    3. detection결과를 postprocessing: Non Maximum Suppression\n",
    "    4. postprocessing한 결과를 반환.\n",
    "    \"\"\"\n",
    "    # 1. preprocessing\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    # 2. 추론\n",
    "    predict_dic = detection_model.predict(image,shapes)\n",
    "    # 3. post processing\n",
    "    result = detection_model.postprocess(predict_dic, shapes)\n",
    "    # 4. 반환\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'id': 1, 'name': 'one'},\n",
       " 2: {'id': 2, 'name': 'two'},\n",
       " 3: {'id': 3, 'name': 'three'},\n",
       " 4: {'id': 4, 'name': 'four'},\n",
       " 5: {'id': 5, 'name': 'five'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(LABEL_MAP_FILE_PATH)\n",
    "print(type(category_index))\n",
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 웹캠으로 부터 이미지를 받아서 추론한 결과를 화면에 보여주기.\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print('webcam failed')\n",
    "# print(cap.isOpened())\n",
    "# 웹캠의 width/height 조회\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read() # 한 frame 읽기.\n",
    "    if not ret:\n",
    "        print(\"이미지를 읽지 못함\")\n",
    "        break\n",
    "        \n",
    "    frame = cv2.flip(frame, 1) # 좌우 반전.\n",
    "    \n",
    "    # BGR => RGB (모델이 학습할때 RGB 모드로 학습했기 때문에 같은형식으로 변환)\n",
    "    image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 0번축을 늘린후, Tensor로 변환\n",
    "    input_tensor = tf.convert_to_tensor(image_np[np.newaxis, ...], dtype=tf.float32)\n",
    "    \n",
    "    # 추론\n",
    "    post_detection = detect_func(input_tensor) # 전처리->추론->후처리\n",
    "    \n",
    "    \n",
    "    num_detections = int(post_detection.pop('num_detections'))\n",
    "    # 추론한 결과들을 num_detections 개수(detection한 물체의 개수)만큼의 값만 남긴다. 결과가 Tensor로 반환되는 것을 ndarray로 반환.\n",
    "    detections = { key:value[0, :num_detections].numpy() for key, value in post_detection.items()}\n",
    "    # 새로 구성한 결과 dictionary(detections)에 num_detections 값을 추가\n",
    "    detections['num_detections'] = num_detections\n",
    "    # detection_classes는 검출한 box의 class값을 label encoding된 값으로 가진다. float32로 반환되는 것을 int로 변환 처리\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    \n",
    "    \n",
    "    MIN_CONF_THRESH =0.5 # 물체가 있을 confidence score가 0.5이상인 bounding box만 나오도록 하겠다.\n",
    "    image_np_with_detection = image_np.copy() # detection한 원본 이미지의 카피본을 생성.\n",
    "    img = viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detection, # 추론한 원본이미지,\n",
    "        detections['detection_boxes'], # bounding box좌표\n",
    "        detections['detection_classes'] + 1, # bounding box내의 물체 index(class확률에서 0은 첫번째 label, label map의 id는 1부터 시작하기 때문에 + 1을 해준다.)\n",
    "        detections['detection_scores'], # bounding box내에 물체가 있을 확률(confidence score)\n",
    "        category_index,\n",
    "        use_normalized_coordinates = True, # bounding box의 좌표들이 normalize되었는지 여부\n",
    "        max_boxes_to_draw=100, # 최대 몇개의 박스를 칠 것인지(default:20)\n",
    "        min_score_thresh=MIN_CONF_THRESH # confidence score가 얼마 이상인 bounding box만 나오도록 하겠다.\n",
    "    )\n",
    "    # 결과 image를 RGB->BGR\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    # 화면에 출력\n",
    "    cv2.imshow('frame', img)\n",
    "    if cv2.waitKey(1) > 0:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post processing  결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('five_a.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = img[np.newaxis, ...]\n",
    "input_tensor = tf.convert_to_tensor(img, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_detection = detect_func(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['detection_boxes', 'detection_scores', 'detection_classes', 'num_detections', 'raw_detection_boxes', 'raw_detection_scores', 'detection_multiclass_scores', 'detection_anchor_indices'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['num_detections'].numpy() # tensor => ndarray\n",
    "# num_detections: 후처리로 최종 결과로 나온 bounding box의 개수. \n",
    "#전체 bounding box에서 confidence score순으로 내림 차순한 뒤 NMS를 거쳐서 최종적으로 남은 bounding box의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 100, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['detection_boxes'].shape\n",
    "# [1, 100, 4] =>[추론한이미지개수, num_detections, 좌표(x,y,w,h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 100])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bounding box(bbox)에 물체가 있을 확률 = confidence score\n",
    "post_detection['detection_scores'].shape\n",
    "# [1, 100], [추론한이미지개수, num_detections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([1.        , 0.03945891, 0.0358245 , 0.02451506, 0.02186941,\n",
       "       0.01868566, 0.01674229, 0.01609688, 0.01506179, 0.01422502],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['detection_scores'][0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.3586255 , 0.13050056, 0.9508877 , 0.6253593 ], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['detection_boxes'][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "post_detection['detection_scores'][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['detection_classes'][0,0] +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 100, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 클라스별 확률\n",
    "post_detection['detection_multiclass_scores'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
       "array([9.4400661e-05, 8.1133585e-05, 1.5478390e-02, 6.2484560e-03,\n",
       "       2.4515057e-02, 1.0000000e+00], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['detection_multiclass_scores'][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12804, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_detection['raw_detection_boxes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
